---
title: "Assignment2"
author: "JIANG Rui CHAN Yat Tin"
date: "4/30/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Install packages 
```{r}
install.packages("carData")
install.packages("glmnetUtils")
install.packages("margins")
```

## Load packages 
```{r}
library(carData)
library(glmnetUtils)
library(margins)
library(glmnetUtils)
library(tidyverse)
```

## Dataset Info
The data set contains information on ex-convicts collected during a period of 52 weeks after their release:

1. arrest 1 if arrested.

2. fin yes if received financial aid.

3. Additional variables on age, marital status, work experience, education, and etc.

4. week The week of first arrest after release. 52 if not arrested during the period.

5. The variables emp1–emp52 track their employment status by week with value yes if employed.

Generate a new variable Wks that measures the fraction of time an ex-convict was unemployed before re-arrested or until the end of the 52 weeks period:
```{r}
?Rossi
Rossi_df <- as.data.frame(Rossi)
summary(Rossi)
Rossi$Weeks_worked=0
for (i in 1:nrow(Rossi)){
  last_week_col=Rossi$week[i]+10 #last week before arrest column number
  for (j in 11:last_week_col){
  Rossi$Weeks_worked[i]=Rossi$Weeks_worked[i]+(Rossi[i,j]=="yes")
  }
}
Rossi$Wks=(Rossi$week-Rossi$Weeks_worked)/Rossi$week
```

Part A -- Estimate the following logit model using glm():
1. Report the estimattion results using the summary() command.
2. Report the AME for fin including the 95% confidence interval. Does financial aid have a significant effect on re-arrests?
```{r}
Logit <- glm(arrest~fin+age+race+wexp+mar+paro+prio+educ+Wks,data=Rossi,family=binomial(link="logit"))
coef(summary(Logit))
summary(margins(Logit,variables="fin"))
```
 

Since the p-value is 0.0925 > 0.05, financial aid does not have a significant effect on re-arrests.
 
Part B
```{r}
# Use glmnet() to calculate adaptive LASSO
Lasso <- glmnet(arrest~fin+age+race+wexp+mar+paro+prio+educ+Wks,data=Rossi,family="binomial",alpha=0,lambda=0,standardize=FALSE, intercept=FALSE)

# Focus on finyes 
coef(Lasso)

# Generate the penalty weights
w=1/abs(coef(Lasso)[-1])
w[1:2]=0
w
```
 
Part C 
```{r}
set.seed(6083,sample.kind="Rejection")
CV_AL=cv.glmnet(arrest~fin+age+race+wexp+mar+paro+prio+educ+Wks,data=Rossi,family="binomial",alpha=0,standardize=FALSE, intercept=FALSE,penalty.factor=w)
coef(CV_AL,CV_AL$lambda.1se)
```
 
Part D
```{r}
X=model.matrix(arrest~fin+age+race+wexp+mar+paro+prio+educ+Wks,data=Rossi)[,-1]
y=Rossi$arrest

# Adjust w
adjust_w <- w
adjust_w <- w[c(2,3,4,5,6,8,10,11,12)]
adjust_w 

CV=cv.glmnet(X,y,family="binomial",alpha=0,standardize=FALSE, penalty.factor=adjust_w, nfolds=10)
plot(CV)
coef(CV,s=CV$lambda.1se)
```
Part E
```{r}
Post.Logit <- glm(arrest~fin+age+wexp,data=Rossi,family=binomial(link="logit"))
coef(summary(Post.Logit))
summary(margins(Post.Logit))
```


Question 2: MC simulations for different choices of the Lasso penalty parameter λ 
Note: if you want to use one regressor, consider this expression : lasso <- cv.glmnet(cbind(0, x1),y,alpha = 1)
Part a.
```{r}
dgp <- function(beta_one, sigma){
  # Parameter
  # 1. beta_one 
  # 2. sigma 
  
  # Generate beta0
  matrix_beta_zero <- matrix(1, 30, 1)
  
  # Generate X1,1 .... X30,1
  matrix_x <- matrix(rnorm(30*1, mean=0,sd=1), 30, 1)
  
  # Generate 300 irrelevant X variables 
  matrix_x_ir <- matrix(rnorm(30*300, mean=0,sd=1), 30, 300)
  
  # Generate beta_one *  matrix_x
  beta_one_matrix_x <-  beta_one*matrix_x
  
  # Generate Ui 
  matrix_u <- matrix(rnorm(30*1, mean=0,sd=1), 30, 1)
  
  # Generate sigma * U
  sigma_matrix_u <- sigma * matrix(rnorm(30*1, mean=0,sd=1), 30, 1)
  
  # Generate Yi
  y <- matrix_beta_zero + beta_one_matrix_x + sigma_matrix_u
  
  # Rename matrix columns 
  colnames(y) <- "yi"
  colnames(matrix_beta_zero) <- "beta_zero"
  colnames(beta_one_matrix_x) <- "beta_one_x"
  colnames(sigma_matrix_u) <- "sigma_u"
  # colnames(matrix_x_ir) <- "Irrelevant_x"
  
  # cbind matrixes 
  dataset <- cbind(y,matrix_beta_zero,beta_one_matrix_x,sigma_matrix_u,matrix_x_ir)
  
   # Convert matrix to dataframe 
  dataset.data.frame <- as.data.frame(dataset)
  
  return(dataset.data.frame)
  
}
```

Test 
```{r} 
# Test function dgp
dataset_test <- dgp(10,1.5)

# Test lambda 1 and 2 expression
lambda_1 <- 2 * 1.5 * ((2 * log(1 * 300) / 30)**(0.5))
lambda_2 <- 2 * ((2 * log(1 * 300) / 30) ** (0.5))

# lambda 3 and 4 -- # Find amount of penalty lambda by cross validation and search for lambda that gives min MSE 
PredictorVariables <- paste("V", 5:304, sep="") ## particularly construct 300 control variables 
Formula <- formula(paste("yi ~ beta_one_x +", 
     paste(PredictorVariables, collapse=" + ")))
Formula
X <- model.matrix(Formula, data=dataset_test)[,-1]  ## Model equation 
Y <- dataset_test$yi # Model equation 
cv_lambda_lasso <- cv.glmnet(X, Y, alpha=1) 
plot(cv_lambda_lasso)
cv_lambda_lasso # check MSE
# cv_lambda_lasso$glmnet.fit
lambda_3 <- cv_lambda_lasso$lambda.1se
lambda_4 <- cv_lambda_lasso$lambda.min

# 4 models 
# model 1
lasso1.model <- glmnet(X,Y,alpha=1, lambda=lambda_1)
lasso1.model $beta

lasso2.model <- glmnet(X,Y,alpha=1, lambda=lambda_2)
lasso2.model $beta

lasso3.model <- glmnet(X,Y,alpha=1, lambda=lambda_3)
lasso3.model $beta

lasso4.model <- glmnet(X,Y,alpha=1, lambda=lambda_4)
lasso4.model $beta

```

Part b
```{r}
dgp_mc <- function(n,beta_one,sigma){
  # parameter
  # 1. n -- number of mc repetitions 
  # 2. beta_one
  # 3. sigma
  dataset_test <- data.frame(matrix(ncol=))
  for(i in 1:n){
    set.seed(i)
    
    # Generate dataset 
    dataset_b <- dgp(beta_one,sigma)

    lambda_1 <- 2 * sigma * ((2 * log(n * 300) / 30)**(0.5))
    lambda_2 <- 2 * ((2 * log(n * 300) / 30)**(0.5))
    cv_model <- cv.glmnet(beta_one, yi, data=dataset_b, alpha=1)
    lambda_3 <-cv_model$lambda.1se
    lambda_4 <- cv_model$lambda.min

    # lambda 1 and Lasso including the first regressor Xi,1,
    lasso1 <- glmnet(yi ~ beta_one_x,data=dataset_b,alpha=1, lambda=lambda_1)

    # lambda 1 and Lasso inclduing at least one of the irrelevant regressors
    lasso2 <-  glmnet(yi ~ beta_one_x + Irrelevant_x,data=dataset_b,alpha=1,lambda=lambda_1)

    # lambda 2
    lasso3 <- glmnet(yi ~ beta_one_x,data=dataset_b,alpha=1, lambda=lambda_2)
    lasso4 <-  glmnet(yi ~ beta_one_x + Irrelevant_x,data=dataset_b,alpha=1,lambda=lambda_2)

    # lambda 3
    lasso5 <- glmnet(yi ~ beta_one_x,data=dataset_b,alpha=1, lambda=lambda_3)
    lasso6 <-  glmnet(yi ~ beta_one_x + Irrelevant_x,data=dataset_b,alpha=1,lambda=lambda_3)

    # lambda 4
    lasso7 <- glmnet(yi ~ beta_one_x,data=dataset_b,alpha=1, lambda=lambda_4)
    lasso8 <-  glmnet(yi ~ beta_one_x + Irrelevant_x,data=dataset_b,alpha=1,lambda=lambda_4)
  
    
     
  }
  
  

  
 
}
```

```{r}

```




 
